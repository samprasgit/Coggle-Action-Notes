{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT（Bidirectional Encoder Representations from Transformers）是一种预训练语言模型，它可以生成高质量的文本表示，并被广泛应用于文本分类任务。BERT使用双向Transformer编码器来捕捉文本中的上下文信息，从而获得更好的表示效果。\n",
    "\n",
    "- 步骤1：加载BERT模型，对文本进行编码\n",
    "- 步骤2：BERT模型的训练，验证和预测\n",
    "- 步骤3：通过上述步骤，请回答下面问题\n",
    "    - BERT模型精度与文本最大长度是否相关？\n",
    "    - BERT模型分类时最后全连接层的输入是什么含义？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
